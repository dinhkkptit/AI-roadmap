# ğŸŸ¦ **TUáº¦N 8: RAG (Retrieval-Augmented Generation)**

Tuáº§n nÃ y cá»±c ká»³ quan trá»ng vÃ¬ **80% há»‡ thá»‘ng AI thá»±c táº¿** (chatbot doanh nghiá»‡p, trá»£ lÃ½ luáº­t, trá»£ lÃ½ y táº¿, há»‡ thá»‘ng tÃ¬m kiáº¿m thÃ´ng minhâ€¦) Ä‘á»u dá»±a vÃ o **RAG**.  
Báº¡n sáº½ há»c toÃ n bá»™ pipeline: tá»« **Embedding, Chunking, Retriever, Reranker, Context Builder, Generator**, Ä‘áº¿n **Evaluation & Optimization**.

---

# ğŸš€ **Tá»”NG QUAN RAG (Retrieval-Augmented Generation)**

**RAG = mÃ´ hÃ¬nh LLM + cÃ´ng cá»¥ truy xuáº¥t dá»¯ liá»‡u (retriever)**  
GiÃºp LLM tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u tháº­t (PDF, web, tÃ i liá»‡u ná»™i bá»™) thay vÃ¬ Ä‘oÃ¡n.

> ğŸ’¡ RAG = Search + LLM  
> â†’ Tiáº¿t kiá»‡m chi phÃ­  
> â†’ KhÃ´ng cáº§n fine-tune nhiá»u  
> â†’ Giáº£m hallucination

---

# ğŸŸ¦ **1. Kiáº¿n trÃºc tá»•ng thá»ƒ cá»§a RAG**

Pipeline chuáº©n:

`User Query      â†“ Query Preprocessing      â†“ Embedding Model      â†“ Vector Database (retriever)      â†“ Reranker (re-rank top K)      â†“ Context Builder (chunk assembly)      â†“ LLM Generator      â†“ Final Answer`

RAG hiá»‡n Ä‘áº¡i = **Retriever + Reranker + Generator**.

---

# ğŸŸ© **2. Embedding (Vector Representation)**

Embedding lÃ  trÃ¡i tim cá»§a RAG.

## 2.1. Loáº¡i embedding cho RAG:

âœ” Text embedding  
âœ” Multi-lingual embedding  
âœ” Document embedding  
âœ” Query embedding

## 2.2. MÃ´ hÃ¬nh embedding tá»‘t nháº¥t hiá»‡n nay:

- **BGE-M3 (SOTA)**
    
- BGE large
    
- E5-Mistral
    
- Instructor-XL
    
- GTE Large
    
- mContriever (Meta)
    

## 2.3. YÃªu cáº§u embedding tá»‘t:

- Semantic similarity cao
    
- Äa ngÃ´n ngá»¯
    
- Zero-shot robust
    
- KhÃ´ng drift qua domain
    

---

# ğŸŸ¦ **3. Chunking (TÃ¡ch tÃ i liá»‡u)**

Náº¿u chunk sai â†’ RAG tháº¥t báº¡i.

## 3.1. CÃ¡c chiáº¿n lÆ°á»£c chunking:

- **Fixed-size** (512â€“1024 chars)
    
- **Recursive Chunking** (tá»‘t nháº¥t cho PDF)
    
- **Semantic Chunking** (chia theo topic)
    
- **Windowed Chunking** (overlap: 50â€“100 tokens)
    

## 3.2. Best practice:

- Chunk size: **512â€“1024 tokens**
    
- Overlap: **50â€“150 tokens**
    
- DÃ¹ng LangChain â€œRecursiveCharacterTextSplitterâ€
    

---

# ğŸŸ§ **4. Vector Database (Retriever)**

NÆ¡i lÆ°u trá»¯ embedding cá»§a tÃ i liá»‡u.

## 4.1. Vector DB phá»• biáº¿n:

- **FAISS** (nhanh nháº¥t, offline)
    
- **Milvus**
    
- **Weaviate**
    
- **Qdrant**
    
- **Pinecone** (SaaS)
    

## 4.2. Index phá»• biáº¿n:

- HNSW
    
- IVF
    
- FlatIP
    
- ScaNN
    

## 4.3. CÃ¡c ká»¹ thuáº­t tÄƒng cháº¥t lÆ°á»£ng:

- Re-ranking
    
- Hybrid search (keyword + vector)
    
- kNN threshold
    
- Filter metadata
    

---

# ğŸŸ¦ **5. Retriever (Láº¥y dá»¯ liá»‡u)**

Äáº§u vÃ o = query â†’ embedding  
Äáº§u ra = top K chunks

CÃ¡c phÆ°Æ¡ng phÃ¡p retriever:

- Dense retriever (embedding-based)
    
- Sparse retriever (BM25)
    
- Hybrid (BM25 + Embedding) â† máº¡nh nháº¥t
    

---

# ğŸŸ¥ **6. Reranker (Cá»±c quan trá»ng â€“ tÄƒng Ä‘á»™ chÃ­nh xÃ¡c)**

Reranker = mÃ´ hÃ¬nh cross-encoder Ä‘Ã¡nh giÃ¡ láº¡i tá»«ng chunk xem cÃ³ liÃªn quan tháº­t khÃ´ng.

## Reranker tá»‘t nháº¥t:

- **BGE-Reranker-Large**
    
- **Cohere Reranker**
    
- **ColBERTv2**
    
- **Qwen2-Reranker**
    

## CÃ¡ch hoáº¡t Ä‘á»™ng:

Trong retriever:

`Embedding(query) â†’ retrieve top 20`

Trong reranker:

`CrossEncoder(query, chunk) â†’ score Top 5 (after re-ranking)`

â¡ TÄƒng Ä‘á»™ chÃ­nh xÃ¡c 30â€“60%.

---

# ğŸŸ¦ **7. Context Builder (XÃ¢y dá»±ng bá»‘i cáº£nh)**

LLM ráº¥t nháº¡y cáº£m vá»›i **context format**.

## Chiáº¿n lÆ°á»£c:

- Sorting theo Ä‘iá»ƒm liÃªn quan
    
- Chunk merging
    
- Context window tá»‘i Æ°u (4kâ€“128k)
    
- Prompt template chuáº©n RAG
    
- Citations
    

VÃ­ dá»¥ prompt RAG tá»‘t:

`You are a retrieval-based assistant. Use ONLY the provided context to answer. If not found, say "I don't know".  Context: {{documents}}  Question: {{query}}`

---

# ğŸŸ© **8. Generator (LLM táº¡o cÃ¢u tráº£ lá»i)**

Báº¡n cÃ³ thá»ƒ dÃ¹ng:

- LLaMA 3
    
- Qwen 2
    
- Mistral
    
- Gemma
    
- GPT-4/4o náº¿u cáº§n cháº¥t lÆ°á»£ng cao
    

---

# ğŸŸ¦ **9. RAG nÃ¢ng cao (Advanced RAG)**

## 9.1. RAG Fusion

- Táº¡o nhiá»u query tá»« 1 query
    
- TÄƒng kháº£ nÄƒng tÃ¬m Ä‘Ãºng
    

## 9.2. HyDE (Hypothetical Document Embedding)

LLM táº¡o tÃ i liá»‡u â€œgiáº£ láº­pâ€ vá» query â†’ embedding â†’ retrieve  
â¡ cáº£i thiá»‡n accuracy cá»±c máº¡nh.

## 9.3. Query Rewriting

LLM cáº£i thiá»‡n cÃ¢u há»i ngÆ°á»i dÃ¹ng.

## 9.4. Multi-vector Retrieval

DÃ¹ng nhiá»u embedding cho má»™t document (passage-level).

## 9.5. Graph RAG

XÃ¢y knowledge graph â†’ traverse theo quan há»‡.

## 9.6. Long-context RAG

DÃ¹ng LLM context 128k â€“ 1M â†’ bá» vector DB (chá»‰ vá»›i tÃ i liá»‡u <1M tokens).

---

# ğŸŸ¥ **10. ÄÃ¡nh giÃ¡ RAG (RAG Evaluation)**

## 10.1. Metrics:

- **RAGAS** (SOTA)
    
- Faithfulness
    
- Answer relevance
    
- Context recall
    
- Context precision
    
- Citation accuracy
    

## 10.2. LLM-based evaluation

DÃ¹ng GPT-4o, Claude 3 Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ output.

---

# ğŸŸ¦ **11. CÃ´ng cá»¥ RAG hiá»‡n Ä‘áº¡i**

|Tool|Máº¡nh vá»|
|---|---|
|**LlamaIndex**|dá»±ng RAG end-to-end|
|**LangChain**|pipeline linh hoáº¡t|
|**Haystack**|retriever chuyÃªn nghiá»‡p|
|**Chroma**|local vector DB|
|**Milvus/Qdrant**|production vector DB|

---

# ğŸ¯ **TÃ³m táº¯t Tuáº§n 8**

|ThÃ nh pháº§n|Vai trÃ²|
|---|---|
|Embedding|biá»ƒu diá»…n cÃ¢u thÃ nh vector|
|Chunking|chia tÃ i liá»‡u há»£p lÃ½|
|Retriever|tÃ¬m top K documents|
|Reranker|xáº¿p láº¡i cháº¥t lÆ°á»£ng|
|Generator|LLM táº¡o cÃ¢u tráº£ lá»i|
|Context builder|tá»• chá»©c dá»¯ liá»‡u|
|Advanced RAG|Fusion, HyDE, Query Rewrite|
|Evaluation|RAGAS, LLM judge|
